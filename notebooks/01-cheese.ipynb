{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, run the code cell below for a nicer layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { margin-top: 3em !important; }\n",
       "h2 { margin-top: 2em !important; }\n",
       "#notebook-container { \n",
       "    width: 50% !important; \n",
       "    min-width: 800px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "h1 { margin-top: 3em !important; }\n",
    "h2 { margin-top: 2em !important; }\n",
    "#notebook-container { \n",
    "    width: 50% !important; \n",
    "    min-width: 800px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheese! Jaccard!\n",
    "\n",
    "In the lecture we computed the Jaccard similarity of a few cheeses. We are doing the same here, but on a larger scale! Here's our plan:\n",
    "\n",
    "1. Have a look at the data\n",
    "2. Come up with a few questions\n",
    "3. Prepare some tools\n",
    "4. Load the data\n",
    "5. Analyse it\n",
    "6. Critique\n",
    "\n",
    "This is roughly how we will conduct exploratory data analysis! In a real example, we would probably find in step 5. that our analysis did not work and we would to go back to step 2. to adapt the questions we want to answer.\n",
    "\n",
    "## Step 1: Look at the data\n",
    "\n",
    "First, let's have a look at the data in `01-resources/cheeses.txt` (use your favourite \n",
    "text editor, like `notepad`, `notepad++`, `sublime`...). The first few lines look as follows:\n",
    "\n",
    "```\n",
    "champignon de luxe garlic,soft,soft-ripened,garlicky,herbaceous,herbal,spicy,cream,...\n",
    "bleu dauvergne,semi-soft,artisan,buttery,creamy,grassy,herbaceous,salty,spicy,tangy,...\n",
    "paesanella caciotta,semi-soft,mild,milky,buttery,milky,white,buttery,chewy and soft,...\n",
    "daphnes aged goat cheese,semi-soft,artisan,piquant,sharp,tart,goaty,dense and smooth,...\n",
    "olomoucke tvaruzky,soft,soft-ripened,pungent,spicy,strong,yellow,crumbly and soft\n",
    "\n",
    "```\n",
    "\n",
    "So the values are **comma-separated** and we have one entry per line, with the first value\n",
    "being the cheese's name and the remainder it's description. This format is easy enough\n",
    "that we will parse it using only basic Python, no need for a library.\n",
    "\n",
    "A few notes we should take: the file has 1829 lines, so unless there is something unexpected somewhere in the middle we should get 1829 cheeses out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Come up with questions\n",
    "\n",
    "What do we want to know about cheese similarity? Let us imagine some scenarios\n",
    "for the data analysis. First, let's say we have a business and we know that \n",
    "the cheese `doublet` is very successful in our target demographic, and we would like to suggest very similar cheeses to them.\n",
    "\n",
    "> **Question 1:** Which cheese in our dataset is most similar to `doublet`?\n",
    "  How do they differ?\n",
    "\n",
    "Second, assume we are a cheese manufacturer that wants to survey market. In particular we would like to know what combinations of cheese properties\n",
    "are successful. For that reason, we would like to find the **most common** property set.\n",
    "\n",
    "> **Question 2:** What is the most frequent property set?\n",
    "\n",
    "Finally, let's say we are working for cheese award which prizes the most\n",
    "distinct, innovative cheeses. From our dataset, we want to create a shortlist\n",
    "of around a dozen candidates that should enter the competition. We decide that all cheeses that are different (Jaccard similarity < 1) to **every** other cheese in the set should be on the list.\n",
    "\n",
    "> **Question 3:** What are the 'unique' cheeses in our dataset?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preparing tools\n",
    "\n",
    "There is really only one tools that we need that does not come with Python: \n",
    "a function to compute the Jaccard similarity. Let's quickly implement one in the following\n",
    "cell, once we run it (successfully) it will be available to all following cells.\n",
    "\n",
    "> Complete all TODOs in the following cell. You can test the expected result by running the\n",
    "cell below it afterwards, it should print `Everything fine!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is supposed to compute the Jaccard similarity between two sets.\n",
    "def jaccard(A, B):\n",
    "    Ju = len(set(A.union(B)))\n",
    "    Ji = len(set(A.intersection(B)))\n",
    "    if Ju == 0:\n",
    "        if Ji == 0:\n",
    "            J = 1\n",
    "        else:\n",
    "            J = 0\n",
    "    else:\n",
    "        J = Ji/Ju\n",
    "\n",
    "    return J\n",
    "    # return len(A&B)/len(A|B) gives same result provided no dbzero\n",
    "    # TODO: Implement it!  Look at assignment of 1 to J in both cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything fine!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not edit this cell! It will test whether your implementation works as expected.\n",
    "assert jaccard(set(\"ABC\"), set(\"BAC\")) == 1, \"jaccard(..) returned wrong value\"\n",
    "assert jaccard(set(\"ABC\"), set()) == 0, \"jaccard(..) with wrong value\"\n",
    "assert jaccard(set(range(100)), set(range(50))) == .5, \"jaccard(..) with wrong value\"\n",
    "assert jaccard(set(range(100)), set(range(25))) == .25, \"jaccard(..) with wrong value\"\n",
    "assert jaccard(set(), set()) == 1, \"Similiarity of empty set with itself should be 1\"\n",
    "''.join(reversed(\"!enif gnihtyrevE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Loading the data\n",
    "\n",
    "For our purposes it makes sense to load the data into a dictionary: as keys we use the\n",
    "names of the cheeses (they are unique) and as values we will have sets containing the\n",
    "cheese's properties. We use sets here because we will later compute Jaccard similarity!\n",
    "\n",
    "The following cell contains \n",
    "code that is incomplete, please complete it before continuing. \n",
    "\n",
    "> Complete all TODOs in the following cell. You can test the expected result by running the\n",
    "cell below it afterwards, it should print `Everything fine!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829\n"
     ]
    }
   ],
   "source": [
    "cheeses = {} # This dictionary will hold the cheese properties (as sets!),\n",
    "             # using the cheese names as keys.\n",
    " \n",
    "\n",
    "with open('01-resources/cheeses.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        l = l[:-1] # Remove newline character \n",
    "        cheSet = l.split(\",\")\n",
    "        cheeses [cheSet[0]] = set(cheSet[1:])\n",
    "    \n",
    "    print(len(cheeses))\n",
    "        \n",
    "        # TODO: Split the line `l` (using ',' as the separator).\n",
    "        #       The first entry is the name of a cheese, the rest its properties.\n",
    "        #       Store the properties in they dictionary `cheeses` and use the cheese\n",
    "        #       name as the key.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything fine!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not edit this cell! It will test whether your implementation works as expected.\n",
    "assert len(cheeses) == 1829, \"Not the right number of cheeses in the dictionary\"\n",
    "assert \"red cloud\" in cheeses, \"Missing cheese: red cloud\"\n",
    "assert \"limburger\" in cheeses, \"Missing cheese: limburger\"\n",
    "assert \"champignon de luxe garlic\" in cheeses, \"Missing cheese: champignon de luxe garlic\"\n",
    "assert cheeses[\"red cloud\"] == set('semi-hard,artisan,grassy,nutty,barnyardy,goaty,pungent,cream,creamy and firm,washed'.split(',')), \\\n",
    "       \"Properties not a set?\"\n",
    "''.join(reversed(\"!enif gnihtyrevE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5-6: Question 1\n",
    "\n",
    "We will perform steps 5 and 6 on a per-question basis because they do not really relate to each other.\n",
    "\n",
    "> **Question 1:** Which cheese in our dataset is most similar to `doublet`?\n",
    "  How do they differ?\n",
    "\n",
    "Before we get into answering the question fully, let's test our tools. \n",
    "First, let us have a look at the `doublet` entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artisan',\n",
       " 'creamy',\n",
       " 'creamy and smooth',\n",
       " 'ivory',\n",
       " 'mild',\n",
       " 'mold ripened',\n",
       " 'rich',\n",
       " 'soft',\n",
       " 'sweet'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheeses['doublet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our implementation of the Jaccard similarity by comparing `doublet` to, say, `cheddar`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artisan', 'creamy', 'creamy and smooth', 'ivory', 'mild', 'mold ripened', 'rich', 'soft', 'sweet']\n",
      "['artisan', 'compact and crumbly', 'creamy', 'hard', 'pale yellow', 'processed', 'sharp']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sorted(cheeses['doublet']))\n",
    "print(sorted(cheeses['cheddar']))\n",
    "jaccard(cheeses['doublet'], cheeses['cheddar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above two outputs look sensible, our dataset and tools are in order. The above might seem pointless now, but simply testing our methods on simple examples helps to catch mistakes! \n",
    "\n",
    "Let's answer Question 1! We want to find the one cheese that is most similar to <a href=\"https://cheese.com/doublet/\">Doublet</a> according to our dataset.\n",
    "\n",
    "> Complete all TODOs in the following cell or write your own solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar cheese is 'shepherds crook' with a score of 0.64\n"
     ]
    }
   ],
   "source": [
    "best_score = -1\n",
    "most_similar = None\n",
    "doublet_props = cheeses['doublet']\n",
    "for cheese, props in cheeses.items():\n",
    "    if cheese == 'doublet':  \n",
    "        pass\n",
    "    else:\n",
    "        jScore = jaccard(doublet_props, props)\n",
    "        #print(jScore) # test code\n",
    "        if jScore > best_score:\n",
    "            best_score = jScore\n",
    "            most_similar = cheese\n",
    "    # Note, not happy with the check to make sure we are not comparing doublet to itself!\n",
    "    # TODO: Compute jaccard similarity and compare to best_score.\n",
    "    #       If the score is better, set most_similar accordingly.\n",
    "print(\"The most similar cheese is '{}' with a score of {:.2f}\".format(most_similar, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostlike(cheeseb):\n",
    "    best_score = -1\n",
    "    most_similar = None\n",
    "    doublet_props = cheeses[cheeseb]\n",
    "    for cheese, props in cheeses.items():\n",
    "        if cheese == cheeseb:  \n",
    "            pass\n",
    "        else:\n",
    "            jScore = jaccard(doublet_props, props)\n",
    "        #print(jScore) # test code\n",
    "            if jScore > best_score:\n",
    "                best_score = jScore\n",
    "                most_similar = cheese\n",
    "    return best_score\n",
    "    # Note, not happy with the check to make sure we are not comparing doublet to itself!\n",
    "    # TODO: Compute jaccard similarity and compare to best_score.\n",
    "    #       If the score is better, set most_similar accordingly.\n",
    "    #print(\"The most similar cheese is '{}' with a score of {:.2f}\".format(most_similar, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostlike('doublet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for k in cheeses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k in cheeses:\n",
    "    if mostlike(k) <1:\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #b3ffb3; padding: 1.2em; text-align:center;\">\n",
    "Your solution should be either <a href=\"https://cheese.com/shepherds-crook/\">this cheese</a> \n",
    "or <a href=\"https://cheese.com/little-rydings/\">this cheese</a>.\n",
    "</div>\n",
    "\n",
    "###  Critique\n",
    "\n",
    "The question was rather simple and it looks like we got two instead of one\n",
    "cheese. That seems good enough for what we set out to do, at least with\n",
    "this dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5-6: Question 2\n",
    "\n",
    "> **Question 2:** What is the most frequent property set?\n",
    "\n",
    "There are several methods to approach this. I suggest to use the\n",
    "`Counter` data structure from the `collections` library\n",
    "([documentation](https://docs.python.org/3.7/library/collections.html#collections.Counter)). Here is a quick example of how it is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three most common letter are: [('i', 7), ('s', 3), ('c', 3)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for c in 'supercalifragilisticexpialidocious':\n",
    "    counter[c] += 1\n",
    "print(\"The three most common letter are:\", counter.most_common(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: the elements stored in `cheeses` are sets. Python sets are not hashable, which means that we cannot use them as dictionary keys or `Counter` keys. However, a Python set can easily be converted into a `frozenset` which _is_ hashable.\n",
    "\n",
    "> Write a piece of code that answers Question 2 in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common property is: [(frozenset({'soft'}), 12), (frozenset({''}), 8), (frozenset({'hard'}), 5), (frozenset({'semi-hard'}), 4), (frozenset({'semi-soft', 'creamy', 'milky', 'elastic', 'sweet', 'rindless', 'salty', 'white'}), 2), (frozenset({'semi-soft', 'creamy', 'rich', 'yellow', 'salty', 'spicy', 'aromatic', 'strong'}), 2), (frozenset({'buttery', 'citrusy', 'nutty', 'creamy', 'yellow', 'soft-ripened', 'soft', 'salty', 'smooth and spreadable', 'earthy', 'bloomy'}), 2), (frozenset({'washed'}), 2), (frozenset({'tangy', 'springy and stringy', 'yellow', 'soft', 'salty', 'spicy', 'earthy', 'sharp', 'natural', 'strong'}), 2), (frozenset({'tangy', 'hard', 'piquant', 'brittle', 'artisan', 'yellow', 'firm', 'spicy', 'flaky and open', 'natural', 'aromatic', 'strong'}), 2)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for cheese, props in cheeses.items():\n",
    "    fz = frozenset(props)\n",
    "    counter[fz] += 1\n",
    "print(\"The most common property is:\", counter.most_common(10))\n",
    "\n",
    "#This needs work!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #b3ffb3; padding: 1.2em; text-align:center;\">\n",
    "    Your solution should be a set of properties that appears 12 times in the dataset.\n",
    "</div>\n",
    "\n",
    "###  Critique\n",
    "\n",
    "Go back to your code and output the ten most frequent properties. Do you see a problem? Remember, we asked Question 2 in the context of what finding out \"what combinations of cheese properties are successful\". \n",
    "\n",
    "> Identify the problem with our approach and propose a solution. Write a short text in the cell below\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(Writing this after Felix's reply to my post)\n",
    " \n",
    " This has produced the result that 'soft' is the most common set.  \n",
    " This implies that 'soft' as an entire set is the most common, but that is not what we are looking for.\n",
    " The original data does not hold the same amount of data for each cheese.  \n",
    " Had each cheese had, say, 7 attributes, and all were complete, we would have a better picture.\n",
    " In an ideal world!\n",
    " \n",
    " Solution?... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TODO**: write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5-6: Question 3\n",
    "\n",
    "> **Question 3:** What are the 'unique' cheeses in our dataset?\n",
    "\n",
    "Recall that we defined 'unique' as a cheese that has Jaccard similarity <1 to *all* other cheeses.\n",
    "\n",
    "> Write a piece of code that answers Question 3 in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the highest Jaccard Index for any given cheese\n",
    "\n",
    "def mostlike(cheeseb):\n",
    "    best_score = -1\n",
    "    most_similar = None\n",
    "    doublet_props = cheeses[cheeseb]\n",
    "    for cheese, props in cheeses.items():\n",
    "        if cheese == cheeseb:  \n",
    "            pass\n",
    "        else:\n",
    "            jScore = jaccard(doublet_props, props)\n",
    "        #print(jScore) # test code\n",
    "            if jScore > best_score:\n",
    "                best_score = jScore\n",
    "                most_similar = cheese\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostlike('gorgonzola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760\n"
     ]
    }
   ],
   "source": [
    "#This will print the number of cheeses that do not have an index of 1 with another cheese\n",
    "#It runs quite slow\n",
    "count = 0\n",
    "for k in cheeses:\n",
    "    if mostlike(k) <1:\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1413857424305525"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to calculate the average Jaccard index for a given cheese against all other cheeses:\n",
    "\n",
    "def jaccavg(cheesea):\n",
    "    cheese_props = cheeses[cheesea]\n",
    "    jCount = 0\n",
    "    jAve = 0\n",
    "    for cheese, props in cheeses.items():\n",
    "        jScore = jaccard(cheese_props, props)\n",
    "        jCount +=1\n",
    "        jAve += jScore\n",
    "    jAve -=1\n",
    "    jCount -=1  #this removes the instance in which a cheese is compared to itself\n",
    "    jRet = jAve/jCount\n",
    "    return(jRet) \n",
    "        \n",
    "#jaccavg('cheddar')   # test code\n",
    "jaccavg('doublet')   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18425096836771912\n",
      "0.0038293216630196935\n"
     ]
    }
   ],
   "source": [
    "cheeseInd = {}        #the dictionary which will hold all the average jaccard indices for all cheeses\n",
    "\n",
    "\n",
    "for cheese in cheeses:\n",
    "    cheeseInd[cheese] = jaccavg(cheese) # appends each cheese (as a key) and its average Jaccard index to the dictionary\n",
    "\n",
    "#print(cheeseInd)\n",
    "print(max(cheeseInd.values()))\n",
    "print(min(cheeseInd.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarago river jensens red 0.0038293216630196935\n",
      "aragon 0.0038293216630196935\n",
      "frying cheese 0.0038293216630196935\n",
      "northumberland 0.0038293216630196935\n",
      "bergader 0.0038293216630196935\n",
      "cypress grove chevre 0.0038293216630196935\n",
      "jermi tortes 0.0038293216630196935\n",
      "kanafeh 0.0038293216630196935\n",
      "{'tarago river jensens red': 0.0038293216630196935, 'aragon': 0.0038293216630196935, 'frying cheese': 0.0038293216630196935, 'northumberland': 0.0038293216630196935, 'bergader': 0.0038293216630196935, 'cypress grove chevre': 0.0038293216630196935, 'jermi tortes': 0.0038293216630196935, 'kanafeh': 0.0038293216630196935}\n"
     ]
    }
   ],
   "source": [
    "newCheeseInd = {}\n",
    "for k, v in cheeseInd.items():\n",
    "    if v == (min(cheeseInd.values())):\n",
    "        print(k, v)\n",
    "        newCheeseInd[k] = v\n",
    "print(newCheeseInd)\n",
    "\n",
    "#Next step?  Create a new dict with these 8 cheeses, and their properties, and repeat process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Critique\n",
    "\n",
    "How many 'unique' cheeses did you find? Over 1700? Remember, our goal was to shortlist around a dozen cheeses for our award. Can you think of a way \n",
    "that identifies cheeses that are 'more different' than other cheeses using Jaccard similarity?\n",
    "\n",
    "> Identify the problem with our approach and think of a way to create a shortlist of around a dozen cheeses. Implement it in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: orange\">ðŸ—² Further challenges ðŸ—²</h1>\n",
    "\n",
    "If you solved all of the above and you still have plenty of time left, try the following challenges!\n",
    "\n",
    "1. Write the solution to Question 2 in a single line of code.\n",
    "2. Repeat the analysis of Question 2 but solve the problem you identified\n",
    "   in the critique.\n",
    "3. Write a function that takes a cheese name as input and display its picture from Cheese.com in the notebook. \n",
    "\n",
    "Some hints for the third challenge: \n",
    "- The url of the cheese `le cendrillon` is https://cheese.com/le-cendrillon/ \n",
    "- Displaying an image as output of a cell works as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in a name of a cheese, capitalise the first letter: Cheddar\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-1547247b8fb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcheese\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Type in a name of a cheese, capitalise the first letter: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mchurl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://cheese.com/media/img/cheese/%s.jpg\"\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcheese\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://cheese.com/media/img/cheese/%s.jpg\"\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcheese\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "cheese = input(\"Type in a name of a cheese, capitalise the first letter: \")\n",
    "\n",
    "churl = \"https://cheese.com/media/img/cheese/%s.jpg\" (cheese)\n",
    "\n",
    "Image(url=\"https://cheese.com/media/img/cheese/%s.jpg\" (cheese))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sdfjkhg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-31ef0df906af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheeses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheese\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sdfjkhg'"
     ]
    }
   ],
   "source": [
    "a = cheeses[cheese]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
